---
layout:     post
title:      "Surviving the Titanic"
subtitle:   "Predicting Disaster Survival with Classification Models"
date:       2016-10-26 12:00:00
author:     "Kristen Su"
header-img: "img/project-5/titanic-sinking.jpg"
---

<div>
<h2 class="section-heading">Executive Summary</h2>

  <p><b> Dataset: <a href="https://www.kaggle.com/c/titanic/data"> Titanic Database</a> </b></p>
  <p> The goal of the project is to predict the chances of any one passenger surviving the Titanic sinking of 1912, using various classification models to come to the best predictions. The best model turned out to be [  ] with [  ]% accuracy, [  ]% precision and a [  ]% false positive rate.
  </p>

  <p>Project Details:
  <ol>
    <li> Acquire data from AWL PostgreSQL database </li>
    <li> Create classification models to predict likelihood of survival </li>
      <ul>
        <li>Logistic Regression</li>
        <li>kNN Model</li>
        <li>Gridsearch to find optimal parameters for both models</li>
      </ul>
    <li> Examine models through confusion matrices and ROC curves </li>
  </ol>

  <p> This project was inspired by a <a href="https://www.kaggle.com/c/titanic)">Kaggle competition</a><br>
  </p>

<h2 class="section-heading">Women and Children First?</h2>
<p><br>
</p>
<p>
</p>

<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/womenchildren.jpg"></a>
</div>

<p><br>
</p>
<p>
</p>

<p> Remember that line from James Cameron's 1997 classic film <i>Titanic</i>? A chivalrous sentiment but apparently not maritime law in 1912. However, looking over the data it appears that most men honored the sentiment.
</p>
<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/class.png"></a>
</div>
<p>There were nearly twice as many men as women who boarded the ship, but nearly twice as many women that survived than men.
</p>
<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/age.png"></a>
</div>
<p>And looking at age groups (children are under 18, elderly over 40 and adults between 18-40), it looks like you were much more likely to die in the frigid water if you were an adult male.<br>
</p>
<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/factorplot1.png"></a>
</div>
<p>On the other hand, your chances of survival look much better (relative to other men) if you were a high-roller in 1st class. Sorry Jack, you're dead. Ok this is the last reference to <i>Titanic.</i>
</p>
<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/giphy.gif"></a>
</div>
<p></p>
<p>One last point of note, which is surprising, is the difference in survival rates by port of embarkation. Southampton was by far the most popular port for departure, so it makes sense there are more people who died. However the chances of survival are lower than the other ports. It may be that more people that got on at Southampton that had third class cabins. The below regression chart also shows a dense clutter of people who would be grouped in the adult bin and we know that adults had the lowest survival rates. So a disproportionate number of adults in the third class may have contributed to Southampton's low survival rates. <br>
</p>
<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/port_regressions.png"></a>


<h2 class="section-heading">What Do the Models Say?</h2>
<p></p>
<p></p>

<p>Different classification models were trained and tested on split sample data. The standard 67% was used for model training and 33% for model testing. The features of each of the models are:
<ul>
  <li>sex</li>
  <li>age</li>
  <li>normalized fare</li>
  <li>normalized number of siblings and parents on the ship</li>
  <li>normalized number of parents and children on the ship</li>
  <li><i>all normalization done with StandardScalar in sklearn's preprocessing module </i></li>
  <li>dummy variables:</li>
    <ul>
      <li>title (Mr., Mrs., etc.)</li>
        <ul>
          <li>Sidenote: Jonkheer was my favorite title, an old Dutch honorific which is technically a status and not a "title" ala Earl or Duke. It's the root word for Yonkers according to <a href="https://en.wikipedia.org/wiki/Jonkheer">Wikipedia</a>. Shout out to Yonkers! </li>
          <li>Sidenote part twee: That's twee as in two in Dutch. The Jonkheer who died on the Titanic was a one Johan George Reuchlin. He was a director of the Holland America Line and so got a free ticket on the world's largest, fastest, most luxious ship! And also a free ticket straight to his death. 
          </li>
        </ul>
      <li>port of embarkation</li>
      <li>cabin class</li>
      <li>age groups</li>
    </ul>

<p>For each model, the following metrics were calculated:
  <ul>
    <li>precision</li>
    <li>recall</li>
    <li>accuracy</li>
    <li>false positive rate</li>
    <li>area under ROC curve (AUC ROC)</li>
    <li>area under precision-recall curve (AUC PRC)</li>
    </ul>
</p>

<h3>Clarifying some terms</h3>
<p></p>
<p> If you're a data science wiz, go ahead and skip this section. If not, I'll do my best to convey what these terms mean as it relates to our data. The table below will help you visualize what I describe.
</p>

<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/fptable.png"></a>
</div>
Table source <a href= "https://social.msdn.microsoft.com/profile/Andreas+de+Ruiter+%28Microsoft%29">here</a>.

<p><b>Precision</b>: Measures how many passengers actually survived compared to how many were predicted to survive. <br>
Precision = True Positives / (True Positives + False Positives) <br>
</p>

<p><b>Recall</b>: Measures how many passengers were predicted to survive out of all the passengers that actually survived. <br>
Recall = True Positives / (True Positives + False Negatives)<br>
</p>

<p><b>False Positive Rate</b>: Simply put, it's the inverse of precision. <br>
FPR = False Positives / (True Positives + False Positives) <br>
</p>

<p><b>Accuracy</b>: Also called the F1 score, accuracy for our purposes is the balance between precision and recall. It's the harmonic mean between precision (positive predictive value) and recall (sensitivity) <br>
Accuracy = (Recall x Precision) / (Recall + Precision) x 2
</p>

<h3>Coefficients</h3>

<p></p>
<div align = 'center'>  
    <a href="#">
      <img src="{{ site.baseurl }}/img/project-5/coeffs.png"></a>
</div>

<p> Just to make sense of our model, let's take a look at a few coefficents from the logistic regression.
<ul>
  <li><b>sex</b>: -1.14 makes sense as we set male to 1 and female to 0 and clearly the data shows that if you are a male, your chances of survival are pretty slim. This is also born out by <b>title_Mr</b> with a coefficient of -1.33. </li>

  <li><b> male other </b>: -0.88 shows these gents sacrified for the good of others. Passengers in this category (although few in number) were older men with more distinguished titles than Mr., such as Colonel, Captain or Don. Just guessing from their titles, I wonder if it was a greater sense of duty these men felt or they were just older and didn't make it to the lifeboats in time.</li>
  
  <li><b> port_S </b>: 0.31 coefficient is about ten times lower than the other ports. This may indicate that perhaps more people with third class cabins boarded at Southampton.</li>
  
  <li><b> bin_child </b>: 0.69 is lower than I would like but maybe this is due more to children and babies being physically more vulnerable and weak (therefore unable to survive even if they made it on a lifeboat) than to adults taking their place on the lifeboats. </li>
</ul>
<p> All things considered, the coefficients are in line with my expectations.
</p>

<h2 class="section-heading">Back to the Models</h2>
<p></p>
<p></p>
